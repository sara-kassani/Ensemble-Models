{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score,roc_curve, confusion_matrix, roc_auc_score, auc, f1_score\n",
    "from keras.layers import Dense, Input, Dropout, Activation, Conv2D, MaxPooling2D, Lambda, Flatten, GlobalAveragePooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.layers import Flatten, Input, Dense, Activation, Dropout, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.models import Model, load_model\n",
    "from keras.initializers import he_normal, glorot_normal\n",
    "\n",
    "from keras.regularizers import l2\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "from keras.applications import DenseNet201\n",
    "from keras.applications import DenseNet121\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/train/'\n",
    "test_dir = 'data/test/'\n",
    "\n",
    "extracted_features_dir = \"extracted_features/\"\n",
    "model_name = \"VGG16_DenseNet201-Adam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train/ 0\n",
      "data/train/BCC 100\n",
      "data/train/BKL 100\n",
      "data/train/AKIEC 100\n",
      "******************************\n",
      "data/test/ 0\n",
      "data/test/BCC 10\n",
      "data/test/BKL 10\n",
      "data/test/AKIEC 10\n"
     ]
    }
   ],
   "source": [
    "for root,dirs,files in os.walk(train_dir):\n",
    "    print (root, len(files))\n",
    "\n",
    "print(\"*\"*30)\n",
    "for root,dirs,files in os.walk(test_dir):\n",
    "    print (root, len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height, img_width = 224, 224\n",
    "input_shape = (img_height, img_width, 3)\n",
    "epochs = 10\n",
    "\n",
    "top_model_path = os.path.join(extracted_features_dir, 'model_'+model_name+'_model.h5')\n",
    "top_model_weights_path = os.path.join(extracted_features_dir, 'model_'+model_name+'_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 225 images belonging to 3 classes.\n",
      "Found 75 images belonging to 3 classes.\n",
      "Found 30 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "random_seed = np.random.seed(1142)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    validation_split= 0.25,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    seed = random_seed,\n",
    "    shuffle = False,\n",
    "    subset = 'training',\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    seed = random_seed,\n",
    "    shuffle = False,\n",
    "    subset = 'validation',\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    seed = random_seed,\n",
    "    shuffle = False,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_train_samples: 225\n",
      "nb_validation_samples: 75\n",
      "nb_test_samples: 30\n",
      "\n",
      "predict_size_train: 8\n",
      "predict_size_validation: 3\n",
      "predict_size_test: 1\n",
      "\n",
      " num_classes: 3\n"
     ]
    }
   ],
   "source": [
    "nb_train_samples = len(train_generator.filenames)\n",
    "nb_validation_samples = len(validation_generator.filenames)\n",
    "nb_test_samples = len(test_generator.filenames)\n",
    "\n",
    "predict_size_train = int(math.ceil(nb_train_samples / batch_size))\n",
    "predict_size_validation = int(math.ceil(nb_validation_samples / batch_size))\n",
    "predict_size_test = int(math.ceil(nb_test_samples / batch_size))\n",
    "\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "print(\"nb_train_samples:\", nb_train_samples)\n",
    "print(\"nb_validation_samples:\", nb_validation_samples)\n",
    "print(\"nb_test_samples:\", nb_test_samples)\n",
    "\n",
    "print(\"\\npredict_size_train:\", predict_size_train)\n",
    "print(\"predict_size_validation:\", predict_size_validation)\n",
    "print(\"predict_size_test:\", predict_size_test)\n",
    "\n",
    "print(\"\\n num_classes:\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel1=VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "x1=basemodel1.get_layer('block5_pool').output\n",
    "x1=GlobalAveragePooling2D()(x1)\n",
    "\n",
    "basemodel2=DenseNet201(weights=None,input_tensor = basemodel1.input, include_top=False, input_shape=input_shape)\n",
    "x2 = basemodel2.output\n",
    "x2 = GlobalAveragePooling2D()(x2)\n",
    "\n",
    "merge = concatenate([x1, x2])\n",
    "merge = Dropout(0.6)(merge)\n",
    "preds = Dense(num_classes, activation='softmax')(merge)\n",
    "bottleneck_final_model = Model(inputs=basemodel1.input,outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_features_train = bottleneck_final_model.predict_generator(train_generator, predict_size_train, max_q_size=1, pickle_safe=False)\n",
    "np.save(extracted_features_dir+'bottleneck_features_train_'+model_name+'.npy', bottleneck_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_features_validation = bottleneck_final_model.predict_generator(validation_generator, predict_size_validation)\n",
    "np.save(extracted_features_dir+'bottleneck_features_validation_'+model_name+'.npy', bottleneck_features_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_features_test = bottleneck_final_model.predict_generator(test_generator, predict_size_test)\n",
    "np.save(extracted_features_dir+'bottleneck_features_test_'+model_name+'.npy', bottleneck_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import get_session\n",
    "from keras.backend.tensorflow_backend import clear_session\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "def reset_keras_tf_session():\n",
    "    \"\"\"\n",
    "    this function clears the gpu memory and set the \n",
    "    tf session to not use the whole gpu\n",
    "    \"\"\"\n",
    "    sess = get_session()\n",
    "    clear_session()\n",
    "    sess.close()\n",
    "    sess = get_session()\n",
    "\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    set_session(tf.Session(config=config))\n",
    "\n",
    "\n",
    "reset_keras_tf_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(extracted_features_dir+'bottleneck_features_train_'+model_name+'.npy')\n",
    "validation_data = np.load(extracted_features_dir+'bottleneck_features_validation_'+model_name+'.npy')\n",
    "test_data = np.load(extracted_features_dir+'bottleneck_features_test_'+model_name+'.npy')\n",
    "\n",
    "train_labels = train_generator.classes\n",
    "validation_labels = validation_generator.classes\n",
    "test_labels = test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape : (225, 3)\n",
      "Training Data label Shape : (225,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data Shape : {0}\".format(train_data.shape))\n",
    "print(\"Training Data label Shape : {0}\".format(train_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNeighborsClassifier - KFold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores Mean: 40.0593 and (STDEV 0.0797)\n",
      "Best result for fold 6\n",
      "Best accuracy is 0.5454545454545454\n",
      "Scores of all folds: [0.47826087 0.30434783 0.30434783 0.43478261 0.34782609 0.45454545\n",
      " 0.54545455 0.36363636 0.31818182 0.45454545]\n",
      "Accuracy: 0.40 (+/- 0.16)\n"
     ]
    }
   ],
   "source": [
    "clf  =  KNeighborsClassifier(n_neighbors = 5)\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=5)\n",
    "scoring = 'accuracy'\n",
    "scores = cross_val_score(clf, train_data, train_labels, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "\n",
    "print (\"Scores Mean: %.4f and (STDEV %.4f)\" % (np.mean(scores)*100, np.std(scores)))\n",
    "print (\"Best result for fold %s\" % np.argmax(scores))\n",
    "print (\"Best accuracy is\", (scores[np.argmax(scores)]))\n",
    "print (\"Scores of all folds:\", scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "#### DecisionTreeClassifier - KFold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores Mean: 37.7273 and (STDEV 0.0403)\n",
      "Best result for fold 0\n",
      "Best accuracy is 0.43478260869565216\n",
      "Scores of all folds: [0.43478261 0.43478261 0.39130435 0.39130435 0.34782609 0.31818182\n",
      " 0.40909091 0.31818182 0.36363636 0.36363636]\n",
      "Accuracy: 0.38 (+/- 0.08)\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "scoring = 'accuracy'\n",
    "scores = cross_val_score(clf, train_data, train_labels, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "\n",
    "print (\"Scores Mean: %.4f and (STDEV %.4f)\" % (np.mean(scores)*100, np.std(scores)))\n",
    "print (\"Best result for fold %s\" % np.argmax(scores))\n",
    "print (\"Best accuracy is\", (scores[np.argmax(scores)]))\n",
    "print (\"Scores of all folds:\", scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "#### RandomForestClassifier - KFold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores Mean: 41.4427 and (STDEV 0.0819)\n",
      "Best result for fold 5\n",
      "Best accuracy is 0.5454545454545454\n",
      "Scores of all folds: [0.30434783 0.39130435 0.26086957 0.47826087 0.39130435 0.54545455\n",
      " 0.5        0.45454545 0.40909091 0.40909091]\n",
      "Accuracy: 0.41 (+/- 0.16)\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=5)\n",
    "scoring = 'accuracy'\n",
    "scores = cross_val_score(clf, train_data, train_labels, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "\n",
    "print (\"Scores Mean: %.4f and (STDEV %.4f)\" % (np.mean(scores)*100, np.std(scores)))\n",
    "print (\"Best result for fold %s\" % np.argmax(scores))\n",
    "print (\"Best accuracy is\", (scores[np.argmax(scores)]))\n",
    "print (\"Scores of all folds:\", scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree test accuracies 0.2000\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(criterion='entropy', random_state=1, max_depth=1)\n",
    "ada = AdaBoostClassifier(base_estimator=tree, n_estimators=500, learning_rate=0.1, random_state=1)\n",
    "\n",
    "tree = tree.fit(train_data, train_labels)\n",
    "y_train_pred = tree.predict(train_data)\n",
    "y_test_pred = tree.predict(test_data)\n",
    "tree_test = accuracy_score(test_labels, y_test_pred)\n",
    "print('Decision tree test accuracies %.4f' % (tree_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9822222222222222\n",
      "0.29333333333333333\n",
      "0.4\n",
      "Random Forest test accuracies 0.4000\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(train_data, train_labels)\n",
    "print(clf.score(train_data, train_labels))\n",
    "print(clf.score(validation_data, validation_labels ))\n",
    "print(clf.score(test_data, test_labels))\n",
    "\n",
    "y_test_pred = clf.predict(test_data)\n",
    "clf_test = accuracy_score(test_labels, y_test_pred)\n",
    "print('Random Forest test accuracies %.4f' % (clf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.30      0.37        10\n",
      "           1       0.40      0.40      0.40        10\n",
      "           2       0.36      0.50      0.42        10\n",
      "\n",
      "   micro avg       0.40      0.40      0.40        30\n",
      "   macro avg       0.42      0.40      0.40        30\n",
      "weighted avg       0.42      0.40      0.40        30\n",
      "\n",
      "[[3 4 3]\n",
      " [0 4 6]\n",
      " [3 2 5]]\n",
      "0.4\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, y_test_pred))\n",
    "print(confusion_matrix(test_labels, y_test_pred))\n",
    "print(accuracy_score(test_labels, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 0.5644444444444444\n",
      "Validation accuracy 0.38666666666666666\n",
      "Test accuracy 0.4\n",
      "KNeighbors Classifier test accuracies 0.4000\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=8)\n",
    "clf.fit(train_data, train_labels)\n",
    "print(\"Train accuracy\", clf.score(train_data, train_labels))\n",
    "print(\"Validation accuracy\", clf.score(validation_data, validation_labels ))\n",
    "print(\"Test accuracy\", clf.score(test_data, test_labels))\n",
    "\n",
    "y_test_pred = clf.predict(test_data)\n",
    "clf_test = accuracy_score(test_labels, y_test_pred)\n",
    "print('KNeighbors Classifier test accuracies %.4f' % (clf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.40      0.42        10\n",
      "           1       0.40      0.60      0.48        10\n",
      "           2       0.33      0.20      0.25        10\n",
      "\n",
      "   micro avg       0.40      0.40      0.40        30\n",
      "   macro avg       0.39      0.40      0.38        30\n",
      "weighted avg       0.39      0.40      0.38        30\n",
      "\n",
      "[[4 4 2]\n",
      " [2 6 2]\n",
      " [3 5 2]]\n",
      "0.4\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, y_test_pred))\n",
    "print(confusion_matrix(test_labels, y_test_pred))\n",
    "print(accuracy_score(test_labels, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "##### BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 0.9688888888888889\n",
      "Validation accuracy 0.3333333333333333\n",
      "Test accuracy 0.36666666666666664\n",
      "Bagging Classifier test accuracies 0.3667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = BaggingClassifier(RandomForestClassifier(), n_estimators = 300 )\n",
    "clf.fit(train_data, train_labels)\n",
    "print(\"Train accuracy\", clf.score(train_data, train_labels))\n",
    "print(\"Validation accuracy\", clf.score(validation_data, validation_labels ))\n",
    "print(\"Test accuracy\", clf.score(test_data, test_labels))\n",
    "\n",
    "y_test_pred = clf.predict(test_data)\n",
    "clf_test = accuracy_score(test_labels, y_test_pred)\n",
    "print('Bagging Classifier test accuracies %.4f' % (clf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.20      0.25        10\n",
      "           1       0.45      0.50      0.48        10\n",
      "           2       0.31      0.40      0.35        10\n",
      "\n",
      "   micro avg       0.37      0.37      0.37        30\n",
      "   macro avg       0.37      0.37      0.36        30\n",
      "weighted avg       0.37      0.37      0.36        30\n",
      "\n",
      "[[2 4 4]\n",
      " [0 5 5]\n",
      " [4 2 4]]\n",
      "0.36666666666666664\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, y_test_pred))\n",
    "\n",
    "print(confusion_matrix(test_labels, y_test_pred))\n",
    "print(accuracy_score(test_labels, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "##### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 1.0\n",
      "Validation accuracy 0.36\n",
      "Test accuracy 0.36666666666666664\n",
      "AdaBoost Classifier test accuracies 0.3333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = AdaBoostClassifier(DecisionTreeClassifier(), n_estimators = 300 )\n",
    "clf.fit(train_data, train_labels)\n",
    "print(\"Train accuracy\", clf.score(train_data, train_labels))\n",
    "print(\"Validation accuracy\", clf.score(validation_data, validation_labels ))\n",
    "print(\"Test accuracy\", clf.score(test_data, test_labels))\n",
    "\n",
    "predictions = clf.predict(test_data)\n",
    "clf_test = accuracy_score(test_labels, y_test_pred)\n",
    "print('AdaBoost Classifier test accuracies %.4f' % (clf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.20      0.25        10\n",
      "           1       0.42      0.50      0.45        10\n",
      "           2       0.25      0.30      0.27        10\n",
      "\n",
      "   micro avg       0.33      0.33      0.33        30\n",
      "   macro avg       0.33      0.33      0.33        30\n",
      "weighted avg       0.33      0.33      0.33        30\n",
      "\n",
      "[[2 4 4]\n",
      " [0 5 5]\n",
      " [4 3 3]]\n",
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, y_test_pred))\n",
    "\n",
    "print(confusion_matrix(test_labels, y_test_pred))\n",
    "print(accuracy_score(test_labels, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "##### XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 0.8488888888888889\n",
      "Validation accuracy 0.36\n",
      "Test accuracy 0.36666666666666664\n",
      "XGBClassifier test accuracies 0.3667\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "clf = xgb.XGBClassifier()\n",
    "clf.fit(train_data, train_labels)\n",
    "print(\"Train accuracy\", clf.score(train_data, train_labels))\n",
    "print(\"Validation accuracy\", clf.score(validation_data, validation_labels ))\n",
    "print(\"Test accuracy\", clf.score(test_data, test_labels))\n",
    "\n",
    "y_test_pred = clf.predict(test_data)\n",
    "clf_test = accuracy_score(test_labels, y_test_pred)\n",
    "print('XGBClassifier test accuracies %.4f' % (clf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.20      0.25        10\n",
      "           1       0.43      0.60      0.50        10\n",
      "           2       0.30      0.30      0.30        10\n",
      "\n",
      "   micro avg       0.37      0.37      0.37        30\n",
      "   macro avg       0.35      0.37      0.35        30\n",
      "weighted avg       0.35      0.37      0.35        30\n",
      "\n",
      "[[2 5 3]\n",
      " [0 6 4]\n",
      " [4 3 3]]\n",
      "0.36666666666666664\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, y_test_pred))\n",
    "\n",
    "print(confusion_matrix(test_labels, y_test_pred))\n",
    "print(accuracy_score(test_labels, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
