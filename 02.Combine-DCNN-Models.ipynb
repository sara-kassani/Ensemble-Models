{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 10829193123834747168, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 9214062756\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 10073476783347958625\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "np.random.seed(777)\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Flatten, Input, Dense, Activation, Dropout, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.models import load_model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sklearn\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_classes = 2\n",
    "# batch_size = 4 \n",
    "img_height, img_width = 224, 224\n",
    "input_shape = (img_height, img_width, 3)\n",
    "epochs = 20\n",
    "\n",
    "nb_train_samples = 386\n",
    "nb_validation_samples = 199\n",
    "nb_test_samples = 155"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data_reduced/train/'\n",
    "validation_dir = 'data_reduced/validation'\n",
    "test_dir = 'data_reduced/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 386 images belonging to 2 classes.\n",
      "Found 199 images belonging to 2 classes.\n",
      "Found 155 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "random_seed = np.random.seed(777)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size = 1,\n",
    "    seed = random_seed,\n",
    "    shuffle = True,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size = 1,\n",
    "    seed = random_seed,\n",
    "    shuffle = True,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=1,\n",
    "    seed = random_seed,\n",
    "    shuffle = False,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First OnTop Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 5, 5, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "global_avg_pool (GlobalAvera (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           (None, 2)                 4098      \n",
      "=================================================================\n",
      "Total params: 21,806,882\n",
      "Trainable params: 21,772,450\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "inceptV3_net = InceptionV3(weights='imagenet', include_top=False, input_tensor=Input(shape=input_shape))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(inceptV3_net)\n",
    "model.add(GlobalAveragePooling2D(name='global_avg_pool'))\n",
    "model.add(Dense(output_classes, activation='softmax', name='classifier'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 111, 111, 32) 864         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 111, 111, 32) 96          conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 111, 111, 32) 0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 109, 109, 32) 9216        activation_238[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 109, 109, 32) 96          conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 109, 109, 32) 0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 109, 109, 64) 18432       activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 109, 109, 64) 192         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 109, 109, 64) 0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 54, 54, 64)   0           activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 54, 54, 80)   5120        max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 54, 54, 80)   240         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 54, 54, 80)   0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 52, 52, 192)  138240      activation_241[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 52, 52, 192)  576         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 52, 52, 192)  0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 25, 25, 192)  0           activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 25, 25, 64)   192         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 25, 25, 64)   0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 25, 25, 48)   9216        max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 25, 25, 96)   55296       activation_246[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 25, 25, 48)   144         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 25, 25, 96)   288         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 25, 25, 48)   0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 25, 25, 96)   0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_19 (AveragePo (None, 25, 25, 192)  0           max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 25, 25, 64)   76800       activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 25, 25, 96)   82944       activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 25, 25, 32)   6144        average_pooling2d_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 25, 25, 64)   192         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 25, 25, 64)   192         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 25, 25, 96)   288         conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 25, 25, 32)   96          conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 25, 25, 64)   0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 25, 25, 64)   0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 25, 25, 96)   0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 25, 25, 32)   0           batch_normalization_200[0][0]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_243[0][0]             \n",
      "                                                                 activation_245[0][0]             \n",
      "                                                                 activation_248[0][0]             \n",
      "                                                                 activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 25, 25, 64)   192         conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 25, 25, 64)   0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 25, 25, 96)   55296       activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 25, 25, 48)   144         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 25, 25, 96)   288         conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 25, 25, 48)   0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 25, 25, 96)   0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_20 (AveragePo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 25, 25, 64)   76800       activation_251[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 25, 25, 96)   82944       activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 25, 25, 64)   16384       average_pooling2d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 25, 25, 64)   192         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 25, 25, 64)   192         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 25, 25, 96)   288         conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 25, 25, 64)   192         conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 25, 25, 64)   0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 25, 25, 64)   0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 25, 25, 96)   0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 25, 25, 64)   0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_250[0][0]             \n",
      "                                                                 activation_252[0][0]             \n",
      "                                                                 activation_255[0][0]             \n",
      "                                                                 activation_256[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 25, 25, 64)   192         conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, 25, 25, 64)   0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 25, 25, 96)   55296       activation_260[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 25, 25, 48)   144         conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 25, 25, 96)   288         conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, 25, 25, 48)   0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, 25, 25, 96)   0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_21 (AveragePo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 25, 25, 64)   76800       activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 25, 25, 96)   82944       activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 25, 25, 64)   18432       average_pooling2d_21[0][0]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 25, 25, 64)   192         conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 25, 25, 64)   192         conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 25, 25, 96)   288         conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 25, 25, 64)   192         conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 25, 25, 64)   0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, 25, 25, 64)   0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, 25, 25, 96)   0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, 25, 25, 64)   0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_257[0][0]             \n",
      "                                                                 activation_259[0][0]             \n",
      "                                                                 activation_262[0][0]             \n",
      "                                                                 activation_263[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 25, 25, 64)   192         conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_265 (Activation)     (None, 25, 25, 64)   0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 25, 25, 96)   55296       activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 25, 25, 96)   288         conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_266 (Activation)     (None, 25, 25, 96)   0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 12, 12, 96)   82944       activation_266[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 12, 12, 384)  1152        conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 12, 12, 96)   288         conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, 12, 12, 384)  0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_267 (Activation)     (None, 12, 12, 96)   0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_264[0][0]             \n",
      "                                                                 activation_267[0][0]             \n",
      "                                                                 max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 12, 12, 128)  384         conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_272 (Activation)     (None, 12, 12, 128)  0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 12, 12, 128)  114688      activation_272[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 12, 12, 128)  384         conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_273 (Activation)     (None, 12, 12, 128)  0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 12, 12, 128)  114688      activation_273[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 12, 12, 128)  384         conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 12, 12, 128)  384         conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_269 (Activation)     (None, 12, 12, 128)  0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_274 (Activation)     (None, 12, 12, 128)  0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 12, 12, 128)  114688      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 12, 12, 128)  114688      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 12, 12, 128)  384         conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_226 (BatchN (None, 12, 12, 128)  384         conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_270 (Activation)     (None, 12, 12, 128)  0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, 12, 12, 128)  0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_22 (AveragePo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 12, 12, 192)  172032      activation_270[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 12, 12, 192)  172032      activation_275[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 12, 12, 192)  576         conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 12, 12, 192)  576         conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 12, 12, 192)  576         conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 12, 12, 192)  576         conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_268 (Activation)     (None, 12, 12, 192)  0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_271 (Activation)     (None, 12, 12, 192)  0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_276 (Activation)     (None, 12, 12, 192)  0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, 12, 12, 192)  0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_268[0][0]             \n",
      "                                                                 activation_271[0][0]             \n",
      "                                                                 activation_276[0][0]             \n",
      "                                                                 activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 12, 12, 160)  480         conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_282 (Activation)     (None, 12, 12, 160)  0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 12, 12, 160)  179200      activation_282[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 12, 12, 160)  480         conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_283 (Activation)     (None, 12, 12, 160)  0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 12, 12, 160)  179200      activation_283[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 12, 12, 160)  480         conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 12, 12, 160)  480         conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, 12, 12, 160)  0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_284 (Activation)     (None, 12, 12, 160)  0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 12, 12, 160)  179200      activation_279[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 12, 12, 160)  179200      activation_284[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 12, 12, 160)  480         conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 12, 12, 160)  480         conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, 12, 12, 160)  0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_285 (Activation)     (None, 12, 12, 160)  0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_23 (AveragePo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 12, 12, 192)  215040      activation_280[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 12, 12, 192)  215040      activation_285[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_23[0][0]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 12, 12, 192)  576         conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 12, 12, 192)  576         conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, 12, 12, 192)  576         conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 12, 12, 192)  576         conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, 12, 12, 192)  0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, 12, 12, 192)  0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_286 (Activation)     (None, 12, 12, 192)  0           batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_287 (Activation)     (None, 12, 12, 192)  0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_278[0][0]             \n",
      "                                                                 activation_281[0][0]             \n",
      "                                                                 activation_286[0][0]             \n",
      "                                                                 activation_287[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 12, 12, 160)  480         conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_292 (Activation)     (None, 12, 12, 160)  0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 12, 12, 160)  179200      activation_292[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 12, 12, 160)  480         conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_293 (Activation)     (None, 12, 12, 160)  0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 12, 12, 160)  179200      activation_293[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 12, 12, 160)  480         conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 12, 12, 160)  480         conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_289 (Activation)     (None, 12, 12, 160)  0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_294 (Activation)     (None, 12, 12, 160)  0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 12, 12, 160)  179200      activation_289[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 12, 12, 160)  179200      activation_294[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 12, 12, 160)  480         conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 12, 12, 160)  480         conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_290 (Activation)     (None, 12, 12, 160)  0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_295 (Activation)     (None, 12, 12, 160)  0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_24 (AveragePo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 12, 12, 192)  215040      activation_290[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 12, 12, 192)  215040      activation_295[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 12, 12, 192)  576         conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 12, 12, 192)  576         conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 12, 12, 192)  576         conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 12, 12, 192)  576         conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_288 (Activation)     (None, 12, 12, 192)  0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_291 (Activation)     (None, 12, 12, 192)  0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_296 (Activation)     (None, 12, 12, 192)  0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation_297 (Activation)     (None, 12, 12, 192)  0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_288[0][0]             \n",
      "                                                                 activation_291[0][0]             \n",
      "                                                                 activation_296[0][0]             \n",
      "                                                                 activation_297[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, 12, 12, 192)  576         conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_302 (Activation)     (None, 12, 12, 192)  0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 12, 12, 192)  258048      activation_302[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, 12, 12, 192)  576         conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_303 (Activation)     (None, 12, 12, 192)  0           batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 12, 12, 192)  258048      activation_303[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 12, 12, 192)  576         conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 12, 12, 192)  576         conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_299 (Activation)     (None, 12, 12, 192)  0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_304 (Activation)     (None, 12, 12, 192)  0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 12, 12, 192)  258048      activation_299[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 12, 12, 192)  258048      activation_304[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 12, 12, 192)  576         conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, 12, 12, 192)  576         conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_300 (Activation)     (None, 12, 12, 192)  0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_305 (Activation)     (None, 12, 12, 192)  0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_25 (AveragePo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 12, 12, 192)  258048      activation_300[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, 12, 12, 192)  258048      activation_305[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_258 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_25[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 12, 12, 192)  576         conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, 12, 12, 192)  576         conv2d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, 12, 12, 192)  576         conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_258 (BatchN (None, 12, 12, 192)  576         conv2d_258[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_298 (Activation)     (None, 12, 12, 192)  0           batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_301 (Activation)     (None, 12, 12, 192)  0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_306 (Activation)     (None, 12, 12, 192)  0           batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_307 (Activation)     (None, 12, 12, 192)  0           batch_normalization_258[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_298[0][0]             \n",
      "                                                                 activation_301[0][0]             \n",
      "                                                                 activation_306[0][0]             \n",
      "                                                                 activation_307[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_261 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_261 (BatchN (None, 12, 12, 192)  576         conv2d_261[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_310 (Activation)     (None, 12, 12, 192)  0           batch_normalization_261[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_262 (Conv2D)             (None, 12, 12, 192)  258048      activation_310[0][0]             \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_262 (BatchN (None, 12, 12, 192)  576         conv2d_262[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_311 (Activation)     (None, 12, 12, 192)  0           batch_normalization_262[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_259 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_263 (Conv2D)             (None, 12, 12, 192)  258048      activation_311[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_259 (BatchN (None, 12, 12, 192)  576         conv2d_259[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_263 (BatchN (None, 12, 12, 192)  576         conv2d_263[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_308 (Activation)     (None, 12, 12, 192)  0           batch_normalization_259[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_312 (Activation)     (None, 12, 12, 192)  0           batch_normalization_263[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_260 (Conv2D)             (None, 5, 5, 320)    552960      activation_308[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_264 (Conv2D)             (None, 5, 5, 192)    331776      activation_312[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_260 (BatchN (None, 5, 5, 320)    960         conv2d_260[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_264 (BatchN (None, 5, 5, 192)    576         conv2d_264[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_309 (Activation)     (None, 5, 5, 320)    0           batch_normalization_260[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_313 (Activation)     (None, 5, 5, 192)    0           batch_normalization_264[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_309[0][0]             \n",
      "                                                                 activation_313[0][0]             \n",
      "                                                                 max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_269 (Conv2D)             (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_269 (BatchN (None, 5, 5, 448)    1344        conv2d_269[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_318 (Activation)     (None, 5, 5, 448)    0           batch_normalization_269[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_266 (Conv2D)             (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_270 (Conv2D)             (None, 5, 5, 384)    1548288     activation_318[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_266 (BatchN (None, 5, 5, 384)    1152        conv2d_266[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_270 (BatchN (None, 5, 5, 384)    1152        conv2d_270[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_315 (Activation)     (None, 5, 5, 384)    0           batch_normalization_266[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_319 (Activation)     (None, 5, 5, 384)    0           batch_normalization_270[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_267 (Conv2D)             (None, 5, 5, 384)    442368      activation_315[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_268 (Conv2D)             (None, 5, 5, 384)    442368      activation_315[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_271 (Conv2D)             (None, 5, 5, 384)    442368      activation_319[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_272 (Conv2D)             (None, 5, 5, 384)    442368      activation_319[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_26 (AveragePo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_265 (Conv2D)             (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_267 (BatchN (None, 5, 5, 384)    1152        conv2d_267[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_268 (BatchN (None, 5, 5, 384)    1152        conv2d_268[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_271 (BatchN (None, 5, 5, 384)    1152        conv2d_271[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_272 (BatchN (None, 5, 5, 384)    1152        conv2d_272[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_273 (Conv2D)             (None, 5, 5, 192)    245760      average_pooling2d_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_265 (BatchN (None, 5, 5, 320)    960         conv2d_265[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_316 (Activation)     (None, 5, 5, 384)    0           batch_normalization_267[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_317 (Activation)     (None, 5, 5, 384)    0           batch_normalization_268[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_320 (Activation)     (None, 5, 5, 384)    0           batch_normalization_271[0][0]    \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation_321 (Activation)     (None, 5, 5, 384)    0           batch_normalization_272[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_273 (BatchN (None, 5, 5, 192)    576         conv2d_273[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_314 (Activation)     (None, 5, 5, 320)    0           batch_normalization_265[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_316[0][0]             \n",
      "                                                                 activation_317[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 5, 5, 768)    0           activation_320[0][0]             \n",
      "                                                                 activation_321[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_322 (Activation)     (None, 5, 5, 192)    0           batch_normalization_273[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_314[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_5[0][0]              \n",
      "                                                                 activation_322[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_278 (Conv2D)             (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_278 (BatchN (None, 5, 5, 448)    1344        conv2d_278[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_327 (Activation)     (None, 5, 5, 448)    0           batch_normalization_278[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_275 (Conv2D)             (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_279 (Conv2D)             (None, 5, 5, 384)    1548288     activation_327[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_275 (BatchN (None, 5, 5, 384)    1152        conv2d_275[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_279 (BatchN (None, 5, 5, 384)    1152        conv2d_279[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_324 (Activation)     (None, 5, 5, 384)    0           batch_normalization_275[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_328 (Activation)     (None, 5, 5, 384)    0           batch_normalization_279[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_276 (Conv2D)             (None, 5, 5, 384)    442368      activation_324[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_277 (Conv2D)             (None, 5, 5, 384)    442368      activation_324[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_280 (Conv2D)             (None, 5, 5, 384)    442368      activation_328[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_281 (Conv2D)             (None, 5, 5, 384)    442368      activation_328[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_27 (AveragePo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_274 (Conv2D)             (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_276 (BatchN (None, 5, 5, 384)    1152        conv2d_276[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_277 (BatchN (None, 5, 5, 384)    1152        conv2d_277[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_280 (BatchN (None, 5, 5, 384)    1152        conv2d_280[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_281 (BatchN (None, 5, 5, 384)    1152        conv2d_281[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_282 (Conv2D)             (None, 5, 5, 192)    393216      average_pooling2d_27[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_274 (BatchN (None, 5, 5, 320)    960         conv2d_274[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_325 (Activation)     (None, 5, 5, 384)    0           batch_normalization_276[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_326 (Activation)     (None, 5, 5, 384)    0           batch_normalization_277[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_329 (Activation)     (None, 5, 5, 384)    0           batch_normalization_280[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_330 (Activation)     (None, 5, 5, 384)    0           batch_normalization_281[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_282 (BatchN (None, 5, 5, 192)    576         conv2d_282[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_323 (Activation)     (None, 5, 5, 320)    0           batch_normalization_274[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_325[0][0]             \n",
      "                                                                 activation_326[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 5, 5, 768)    0           activation_329[0][0]             \n",
      "                                                                 activation_330[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_331 (Activation)     (None, 5, 5, 192)    0           batch_normalization_282[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_323[0][0]             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_6[0][0]              \n",
      "                                                                 activation_331[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net = model.layers[0] # show the inceptV3_net layers\n",
    "net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second OnTop Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 111, 111, 32) 864         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 111, 111, 32) 96          conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 111, 111, 32) 0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 109, 109, 32) 9216        activation_238[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 109, 109, 32) 96          conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 109, 109, 32) 0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 109, 109, 64) 18432       activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 109, 109, 64) 192         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 109, 109, 64) 0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 54, 54, 64)   0           activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 54, 54, 80)   5120        max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 54, 54, 80)   240         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 54, 54, 80)   0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 52, 52, 192)  138240      activation_241[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 52, 52, 192)  576         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 52, 52, 192)  0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 25, 25, 192)  0           activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 25, 25, 64)   192         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 25, 25, 64)   0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 25, 25, 48)   9216        max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 25, 25, 96)   55296       activation_246[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 25, 25, 48)   144         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 25, 25, 96)   288         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 25, 25, 48)   0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 25, 25, 96)   0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_19 (AveragePo (None, 25, 25, 192)  0           max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 25, 25, 64)   76800       activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 25, 25, 96)   82944       activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 25, 25, 32)   6144        average_pooling2d_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 25, 25, 64)   192         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 25, 25, 64)   192         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 25, 25, 96)   288         conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 25, 25, 32)   96          conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 25, 25, 64)   0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 25, 25, 64)   0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 25, 25, 96)   0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 25, 25, 32)   0           batch_normalization_200[0][0]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_243[0][0]             \n",
      "                                                                 activation_245[0][0]             \n",
      "                                                                 activation_248[0][0]             \n",
      "                                                                 activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 25, 25, 64)   192         conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 25, 25, 64)   0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 25, 25, 96)   55296       activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 25, 25, 48)   144         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 25, 25, 96)   288         conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 25, 25, 48)   0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 25, 25, 96)   0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_20 (AveragePo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 25, 25, 64)   76800       activation_251[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 25, 25, 96)   82944       activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 25, 25, 64)   16384       average_pooling2d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 25, 25, 64)   192         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 25, 25, 64)   192         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 25, 25, 96)   288         conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 25, 25, 64)   192         conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 25, 25, 64)   0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 25, 25, 64)   0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 25, 25, 96)   0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 25, 25, 64)   0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_250[0][0]             \n",
      "                                                                 activation_252[0][0]             \n",
      "                                                                 activation_255[0][0]             \n",
      "                                                                 activation_256[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 25, 25, 64)   192         conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, 25, 25, 64)   0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 25, 25, 96)   55296       activation_260[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 25, 25, 48)   144         conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 25, 25, 96)   288         conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, 25, 25, 48)   0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, 25, 25, 96)   0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_21 (AveragePo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 25, 25, 64)   76800       activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 25, 25, 96)   82944       activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 25, 25, 64)   18432       average_pooling2d_21[0][0]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 25, 25, 64)   192         conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 25, 25, 64)   192         conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 25, 25, 96)   288         conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 25, 25, 64)   192         conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 25, 25, 64)   0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, 25, 25, 64)   0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, 25, 25, 96)   0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, 25, 25, 64)   0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_257[0][0]             \n",
      "                                                                 activation_259[0][0]             \n",
      "                                                                 activation_262[0][0]             \n",
      "                                                                 activation_263[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 25, 25, 64)   192         conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_265 (Activation)     (None, 25, 25, 64)   0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 25, 25, 96)   55296       activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 25, 25, 96)   288         conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_266 (Activation)     (None, 25, 25, 96)   0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 12, 12, 96)   82944       activation_266[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 12, 12, 384)  1152        conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 12, 12, 96)   288         conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, 12, 12, 384)  0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_267 (Activation)     (None, 12, 12, 96)   0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_264[0][0]             \n",
      "                                                                 activation_267[0][0]             \n",
      "                                                                 max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 12, 12, 128)  384         conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_272 (Activation)     (None, 12, 12, 128)  0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 12, 12, 128)  114688      activation_272[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 12, 12, 128)  384         conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_273 (Activation)     (None, 12, 12, 128)  0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 12, 12, 128)  114688      activation_273[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 12, 12, 128)  384         conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 12, 12, 128)  384         conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_269 (Activation)     (None, 12, 12, 128)  0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_274 (Activation)     (None, 12, 12, 128)  0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 12, 12, 128)  114688      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 12, 12, 128)  114688      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 12, 12, 128)  384         conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_226 (BatchN (None, 12, 12, 128)  384         conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_270 (Activation)     (None, 12, 12, 128)  0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, 12, 12, 128)  0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_22 (AveragePo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 12, 12, 192)  172032      activation_270[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 12, 12, 192)  172032      activation_275[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 12, 12, 192)  576         conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 12, 12, 192)  576         conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 12, 12, 192)  576         conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 12, 12, 192)  576         conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_268 (Activation)     (None, 12, 12, 192)  0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_271 (Activation)     (None, 12, 12, 192)  0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_276 (Activation)     (None, 12, 12, 192)  0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, 12, 12, 192)  0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_268[0][0]             \n",
      "                                                                 activation_271[0][0]             \n",
      "                                                                 activation_276[0][0]             \n",
      "                                                                 activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 12, 12, 160)  480         conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_282 (Activation)     (None, 12, 12, 160)  0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 12, 12, 160)  179200      activation_282[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 12, 12, 160)  480         conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_283 (Activation)     (None, 12, 12, 160)  0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 12, 12, 160)  179200      activation_283[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 12, 12, 160)  480         conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 12, 12, 160)  480         conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, 12, 12, 160)  0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_284 (Activation)     (None, 12, 12, 160)  0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 12, 12, 160)  179200      activation_279[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 12, 12, 160)  179200      activation_284[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 12, 12, 160)  480         conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 12, 12, 160)  480         conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, 12, 12, 160)  0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_285 (Activation)     (None, 12, 12, 160)  0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_23 (AveragePo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 12, 12, 192)  215040      activation_280[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 12, 12, 192)  215040      activation_285[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_23[0][0]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 12, 12, 192)  576         conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 12, 12, 192)  576         conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, 12, 12, 192)  576         conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 12, 12, 192)  576         conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, 12, 12, 192)  0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, 12, 12, 192)  0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_286 (Activation)     (None, 12, 12, 192)  0           batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_287 (Activation)     (None, 12, 12, 192)  0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_278[0][0]             \n",
      "                                                                 activation_281[0][0]             \n",
      "                                                                 activation_286[0][0]             \n",
      "                                                                 activation_287[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 12, 12, 160)  480         conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_292 (Activation)     (None, 12, 12, 160)  0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 12, 12, 160)  179200      activation_292[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 12, 12, 160)  480         conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_293 (Activation)     (None, 12, 12, 160)  0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 12, 12, 160)  179200      activation_293[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 12, 12, 160)  480         conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 12, 12, 160)  480         conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_289 (Activation)     (None, 12, 12, 160)  0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_294 (Activation)     (None, 12, 12, 160)  0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 12, 12, 160)  179200      activation_289[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 12, 12, 160)  179200      activation_294[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 12, 12, 160)  480         conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 12, 12, 160)  480         conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_290 (Activation)     (None, 12, 12, 160)  0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_295 (Activation)     (None, 12, 12, 160)  0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_24 (AveragePo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 12, 12, 192)  215040      activation_290[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 12, 12, 192)  215040      activation_295[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 12, 12, 192)  576         conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 12, 12, 192)  576         conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 12, 12, 192)  576         conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 12, 12, 192)  576         conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_288 (Activation)     (None, 12, 12, 192)  0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_291 (Activation)     (None, 12, 12, 192)  0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_296 (Activation)     (None, 12, 12, 192)  0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation_297 (Activation)     (None, 12, 12, 192)  0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_288[0][0]             \n",
      "                                                                 activation_291[0][0]             \n",
      "                                                                 activation_296[0][0]             \n",
      "                                                                 activation_297[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, 12, 12, 192)  576         conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_302 (Activation)     (None, 12, 12, 192)  0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 12, 12, 192)  258048      activation_302[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, 12, 12, 192)  576         conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_303 (Activation)     (None, 12, 12, 192)  0           batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 12, 12, 192)  258048      activation_303[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 12, 12, 192)  576         conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 12, 12, 192)  576         conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_299 (Activation)     (None, 12, 12, 192)  0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_304 (Activation)     (None, 12, 12, 192)  0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 12, 12, 192)  258048      activation_299[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 12, 12, 192)  258048      activation_304[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 12, 12, 192)  576         conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, 12, 12, 192)  576         conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_300 (Activation)     (None, 12, 12, 192)  0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_305 (Activation)     (None, 12, 12, 192)  0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_25 (AveragePo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 12, 12, 192)  258048      activation_300[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, 12, 12, 192)  258048      activation_305[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_258 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_25[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 12, 12, 192)  576         conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, 12, 12, 192)  576         conv2d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, 12, 12, 192)  576         conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_258 (BatchN (None, 12, 12, 192)  576         conv2d_258[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_298 (Activation)     (None, 12, 12, 192)  0           batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_301 (Activation)     (None, 12, 12, 192)  0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_306 (Activation)     (None, 12, 12, 192)  0           batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_307 (Activation)     (None, 12, 12, 192)  0           batch_normalization_258[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_298[0][0]             \n",
      "                                                                 activation_301[0][0]             \n",
      "                                                                 activation_306[0][0]             \n",
      "                                                                 activation_307[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_261 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_261 (BatchN (None, 12, 12, 192)  576         conv2d_261[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_310 (Activation)     (None, 12, 12, 192)  0           batch_normalization_261[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_262 (Conv2D)             (None, 12, 12, 192)  258048      activation_310[0][0]             \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_262 (BatchN (None, 12, 12, 192)  576         conv2d_262[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_311 (Activation)     (None, 12, 12, 192)  0           batch_normalization_262[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_259 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_263 (Conv2D)             (None, 12, 12, 192)  258048      activation_311[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_259 (BatchN (None, 12, 12, 192)  576         conv2d_259[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_263 (BatchN (None, 12, 12, 192)  576         conv2d_263[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_308 (Activation)     (None, 12, 12, 192)  0           batch_normalization_259[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_312 (Activation)     (None, 12, 12, 192)  0           batch_normalization_263[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_260 (Conv2D)             (None, 5, 5, 320)    552960      activation_308[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_264 (Conv2D)             (None, 5, 5, 192)    331776      activation_312[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_260 (BatchN (None, 5, 5, 320)    960         conv2d_260[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_264 (BatchN (None, 5, 5, 192)    576         conv2d_264[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_309 (Activation)     (None, 5, 5, 320)    0           batch_normalization_260[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_313 (Activation)     (None, 5, 5, 192)    0           batch_normalization_264[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_309[0][0]             \n",
      "                                                                 activation_313[0][0]             \n",
      "                                                                 max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_269 (Conv2D)             (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_269 (BatchN (None, 5, 5, 448)    1344        conv2d_269[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_318 (Activation)     (None, 5, 5, 448)    0           batch_normalization_269[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_266 (Conv2D)             (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_270 (Conv2D)             (None, 5, 5, 384)    1548288     activation_318[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_266 (BatchN (None, 5, 5, 384)    1152        conv2d_266[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_270 (BatchN (None, 5, 5, 384)    1152        conv2d_270[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_315 (Activation)     (None, 5, 5, 384)    0           batch_normalization_266[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_319 (Activation)     (None, 5, 5, 384)    0           batch_normalization_270[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_267 (Conv2D)             (None, 5, 5, 384)    442368      activation_315[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_268 (Conv2D)             (None, 5, 5, 384)    442368      activation_315[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_271 (Conv2D)             (None, 5, 5, 384)    442368      activation_319[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_272 (Conv2D)             (None, 5, 5, 384)    442368      activation_319[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_26 (AveragePo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_265 (Conv2D)             (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_267 (BatchN (None, 5, 5, 384)    1152        conv2d_267[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_268 (BatchN (None, 5, 5, 384)    1152        conv2d_268[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_271 (BatchN (None, 5, 5, 384)    1152        conv2d_271[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_272 (BatchN (None, 5, 5, 384)    1152        conv2d_272[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_273 (Conv2D)             (None, 5, 5, 192)    245760      average_pooling2d_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_265 (BatchN (None, 5, 5, 320)    960         conv2d_265[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_316 (Activation)     (None, 5, 5, 384)    0           batch_normalization_267[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_317 (Activation)     (None, 5, 5, 384)    0           batch_normalization_268[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_320 (Activation)     (None, 5, 5, 384)    0           batch_normalization_271[0][0]    \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation_321 (Activation)     (None, 5, 5, 384)    0           batch_normalization_272[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_273 (BatchN (None, 5, 5, 192)    576         conv2d_273[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_314 (Activation)     (None, 5, 5, 320)    0           batch_normalization_265[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_316[0][0]             \n",
      "                                                                 activation_317[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 5, 5, 768)    0           activation_320[0][0]             \n",
      "                                                                 activation_321[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_322 (Activation)     (None, 5, 5, 192)    0           batch_normalization_273[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_314[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_5[0][0]              \n",
      "                                                                 activation_322[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_278 (Conv2D)             (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_278 (BatchN (None, 5, 5, 448)    1344        conv2d_278[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_327 (Activation)     (None, 5, 5, 448)    0           batch_normalization_278[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_275 (Conv2D)             (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_279 (Conv2D)             (None, 5, 5, 384)    1548288     activation_327[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_275 (BatchN (None, 5, 5, 384)    1152        conv2d_275[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_279 (BatchN (None, 5, 5, 384)    1152        conv2d_279[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_324 (Activation)     (None, 5, 5, 384)    0           batch_normalization_275[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_328 (Activation)     (None, 5, 5, 384)    0           batch_normalization_279[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_276 (Conv2D)             (None, 5, 5, 384)    442368      activation_324[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_277 (Conv2D)             (None, 5, 5, 384)    442368      activation_324[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_280 (Conv2D)             (None, 5, 5, 384)    442368      activation_328[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_281 (Conv2D)             (None, 5, 5, 384)    442368      activation_328[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_27 (AveragePo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_274 (Conv2D)             (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_276 (BatchN (None, 5, 5, 384)    1152        conv2d_276[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_277 (BatchN (None, 5, 5, 384)    1152        conv2d_277[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_280 (BatchN (None, 5, 5, 384)    1152        conv2d_280[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_281 (BatchN (None, 5, 5, 384)    1152        conv2d_281[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_282 (Conv2D)             (None, 5, 5, 192)    393216      average_pooling2d_27[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_274 (BatchN (None, 5, 5, 320)    960         conv2d_274[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_325 (Activation)     (None, 5, 5, 384)    0           batch_normalization_276[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_326 (Activation)     (None, 5, 5, 384)    0           batch_normalization_277[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_329 (Activation)     (None, 5, 5, 384)    0           batch_normalization_280[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_330 (Activation)     (None, 5, 5, 384)    0           batch_normalization_281[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_282 (BatchN (None, 5, 5, 192)    576         conv2d_282[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_323 (Activation)     (None, 5, 5, 320)    0           batch_normalization_274[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_325[0][0]             \n",
      "                                                                 activation_326[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 5, 5, 768)    0           activation_329[0][0]             \n",
      "                                                                 activation_330[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_331 (Activation)     (None, 5, 5, 192)    0           batch_normalization_282[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_323[0][0]             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_6[0][0]              \n",
      "                                                                 activation_331[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_4 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define second model ontop of the first model for the bottleneck features using a GAP layer\n",
    "x = GlobalAveragePooling2D()(net.get_layer('mixed10').output) # 310 is the last inception layer\n",
    "bottleneck_model = Model(net.get_layer('input_4').input, x, name='inception_v3_bottleneck')\n",
    "\n",
    "# This list is as long as Inception's\n",
    "bottleneck_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_bottleneck should connect to the output of bottleneck_model, thus training based on image features.\n",
    "svm_bottleneck = SVC(C=1.0, gamma='auto', probability=True, tol=0.001, verbose=False, decision_function_shape='ovr')\n",
    "\n",
    "# svm_net should connect to the output of full_model, thus training on the output of the deep model.\n",
    "svm_net = SVC(C=1.0, gamma='auto', probability=False, tol=0.001, verbose=False, decision_function_shape='ovr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 386/386 [00:00<00:00, 390.69it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = [], []\n",
    "for _ in tqdm(range(nb_train_samples)):\n",
    "    x, y = train_generator.next()\n",
    "    X_train.append(x[0])\n",
    "    y_train.append(y[0])\n",
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "y_train = np.argmax(y_train, axis=1)\n",
    "# np.save('data/npy/X_train.npy', X_train)\n",
    "# np.save('data/npy/y_train.npy', y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([x.flatten() for x in X_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 199/199 [00:01<00:00, 195.68it/s]\n"
     ]
    }
   ],
   "source": [
    "X_validation, y_validation = [], []\n",
    "for _ in tqdm(range(nb_validation_samples)):\n",
    "    x_val, y_val = validation_generator.next()\n",
    "    X_validation.append(x_val[0])\n",
    "    y_validation.append(y_val[0])\n",
    "X_validation = np.asarray(X_validation)\n",
    "y_validation = np.asarray(y_validation)\n",
    "y_validation = np.argmax(y_validation, axis=1)\n",
    "# np.save('data/npy/X_validation.npy', X_validation)\n",
    "# np.save('data/npy/y_validation.npy', y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validation = np.array([x.flatten() for x in X_validation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 155/155 [00:00<00:00, 198.16it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = [], []\n",
    "for _ in tqdm(range(nb_test_samples)):\n",
    "    x_t, y_t = test_generator.next()\n",
    "    X_test.append(x_t[0])\n",
    "    y_test.append(y_t[0])\n",
    "X_test = np.asarray(X_test)\n",
    "y_test = np.asarray(y_test)\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "# np.save('data/npy/X_test.npy', X_test)\n",
    "# np.save('data/npy/y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array([x.flatten() for x in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (386, 150528)\n",
      "y_train shape: (386,)\n",
      "X_validation shape: (199, 150528)\n",
      "y_validation shape: (199,)\n",
      "X_test shape: (155, 150528)\n",
      "y_test shape: (155,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_validation shape:\", X_validation.shape)\n",
    "print(\"y_validation shape:\", y_validation.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "# plt.imshow(X_train[0])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated p =  0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5, 0.3134715025906736)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#class_distrib_train = np.array(np.sum(train_1hot, axis=0)).flatten()\n",
    "class_distrib_train = np.histogram(y_train, bins=np.arange(0, 1 + output_classes))[0]\n",
    "\n",
    "plt.bar(np.arange(len(class_distrib_train)), class_distrib_train/np.sum(class_distrib_train))\n",
    "# plt.savefig('img/bottleneck_train_distrib.png')\n",
    "print('Estimated p = ', 1/output_classes)\n",
    "\n",
    "class_density_train = class_distrib_train / np.sum(class_distrib_train)\n",
    "\n",
    "np.mean(class_density_train), np.std(class_density_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated p =  0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5, 0.017587939698492483)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#class_distrib_val = np.array(np.sum(val_1hot, axis=0)).flatten()\n",
    "class_distrib_val = np.histogram(y_validation, bins=np.arange(0, 1 + output_classes))[0]\n",
    "\n",
    "plt.bar(np.arange(len(class_distrib_val)), class_distrib_val/np.sum(class_distrib_val))\n",
    "# plt.savefig('img/bottleneck_val_distrib.png')\n",
    "print('Estimated p = ', 1/output_classes)\n",
    "\n",
    "class_density_val = class_distrib_val / np.sum(class_distrib_val)\n",
    "\n",
    "np.mean(class_density_val), np.std(class_density_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('models/bottleneck_datasets.npz', X_train, y_train, X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((386, 150528), (386,), (199, 150528), (199,))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load('models/bottleneck_datasets.npz')\n",
    "\n",
    "train_x = data['arr_0']\n",
    "train_y = data['arr_1']\n",
    "val_x = data['arr_2']\n",
    "val_y = data['arr_3']\n",
    "\n",
    "train_x.shape, train_y.shape, val_x.shape, val_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "### Dimensionality reduction (in case 2048 features is too much) via PCA and LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=200, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# 95% energy was in 200 dimensions or so\n",
    "pca = PCA(n_components=200)\n",
    "\n",
    "pca.fit(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.95290935, 200)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_feats = 200\n",
    "\n",
    "plt.plot(range(len(pca.explained_variance_ratio_[:n_feats])), pca.explained_variance_ratio_[:n_feats])\n",
    "\n",
    "np.sum(pca.explained_variance_ratio_[:n_feats]), len(pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=68, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 95% of energy in 68 dimensions or so\n",
    "lda = LinearDiscriminantAnalysis(n_components=68)\n",
    "\n",
    "lda.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_feats = 68\n",
    "plt.plot(range(len(lda.explained_variance_ratio_[:n_feats])), lda.explained_variance_ratio_[:n_feats])\n",
    "np.sum(lda.explained_variance_ratio_[:n_feats]), len(lda.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((386, 200), (386, 1))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_pca = pca.transform(train_x)\n",
    "train_x_lda = lda.transform(train_x)\n",
    "\n",
    "train_x_pca.shape, train_x_lda.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM 5-fold Crossvalidation w/ acc and f1 (all features, pca or lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   5 out of   5 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished in 85.90s\n",
      "Models took an average 27s to train and another 2s to score\n",
      "Average accuracy was 0.905 +- 0.017 during training\n",
      "Average accuracy was 0.899 +- 0.025 during testing\n",
      "Average F1 was 0.810 +- 0.043 during training\n",
      "Average F1 was 0.790 +- 0.067 during testing\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, StratifiedShuffleSplit\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# f1_micro, f1_macro, f1_weighted\n",
    "scoring = {'accuracy': 'accuracy', 'f1': 'f1_macro'}\n",
    "\n",
    "svm_bottleneck = SVC(C=1.0, gamma='auto', probability=True, tol=0.001, verbose=False, decision_function_shape='ovr')\n",
    "\n",
    "'''\n",
    "svm_bottleneck = LinearSVC(\n",
    "    penalty='l2',\n",
    "    loss='squared_hinge',\n",
    "    tol=0.0001,\n",
    "    C=1.0,\n",
    "    multi_class='ovr',\n",
    "    verbose=0,\n",
    "    max_iter=1000\n",
    ")\n",
    "'''\n",
    "\n",
    "t0 = time.time()\n",
    "scores = cross_validate(svm_bottleneck, train_x, train_y, scoring=scoring, cv=5, \n",
    "                        return_train_score=True, n_jobs=3, verbose=1)\n",
    "# with dimensionality reduction\n",
    "#scores = cross_validate(svm_bottleneck, train_x_pca, train_y, scoring=scoring, cv=5, return_train_score=True, n_jobs=3, verbose=1)\n",
    "#scores = cross_validate(svm_bottleneck, train_x_lda, train_y, scoring=scoring, cv=5, return_train_score=True, n_jobs=3, verbose=1)\n",
    "\n",
    "print('finished in %.2fs' % (time.time() - t0))\n",
    "\n",
    "print('Models took an average %ds to train and another %ds to score' % \n",
    "      (np.mean(scores['fit_time']), np.mean(scores['score_time'])))\n",
    "\n",
    "print('Average accuracy was %.3f +- %.3f during training' % \n",
    "      (np.mean(scores['train_accuracy']), np.std(scores['train_accuracy'])))\n",
    "\n",
    "print('Average accuracy was %.3f +- %.3f during testing' % \n",
    "      (np.mean(scores['test_accuracy']), np.std(scores['test_accuracy'])))\n",
    "\n",
    "print('Average F1 was %.3f +- %.3f during training' % \n",
    "      (np.mean(scores['train_f1']), np.std(scores['train_f1'])))\n",
    "\n",
    "print('Average F1 was %.3f +- %.3f during testing' % \n",
    "      (np.mean(scores['test_f1']), np.std(scores['test_f1'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM train (RBF for probs, LDA feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-7bbb522c500a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbottleneck_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'inceptionv3_notop.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'inceptionv3_full.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python35\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[1;34m(model, to_file, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[1;34m'LR'\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhorizontal\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m     \"\"\"\n\u001b[1;32m--> 132\u001b[1;33m     \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python35\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[0m_check_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mdot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rankdir'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python35\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpydot\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         raise ImportError(\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[1;34m'Failed to import `pydot`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m             \u001b[1;34m'Please install `pydot`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             'For example with `pip install pydot`.')\n",
      "\u001b[1;31mImportError\u001b[0m: Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`."
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(bottleneck_model, to_file='inceptionv3_notop.png')\n",
    "plot_model(full_model, to_file='inceptionv3_full.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 111, 111, 32) 864         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 111, 111, 32) 96          conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 111, 111, 32) 0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 109, 109, 32) 9216        activation_238[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 109, 109, 32) 96          conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 109, 109, 32) 0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 109, 109, 64) 18432       activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 109, 109, 64) 192         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 109, 109, 64) 0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 54, 54, 64)   0           activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 54, 54, 80)   5120        max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 54, 54, 80)   240         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 54, 54, 80)   0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 52, 52, 192)  138240      activation_241[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 52, 52, 192)  576         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 52, 52, 192)  0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 25, 25, 192)  0           activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 25, 25, 64)   192         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 25, 25, 64)   0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 25, 25, 48)   9216        max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 25, 25, 96)   55296       activation_246[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 25, 25, 48)   144         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 25, 25, 96)   288         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 25, 25, 48)   0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 25, 25, 96)   0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_19 (AveragePo (None, 25, 25, 192)  0           max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 25, 25, 64)   76800       activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 25, 25, 96)   82944       activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 25, 25, 32)   6144        average_pooling2d_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 25, 25, 64)   192         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 25, 25, 64)   192         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 25, 25, 96)   288         conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 25, 25, 32)   96          conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 25, 25, 64)   0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 25, 25, 64)   0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 25, 25, 96)   0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 25, 25, 32)   0           batch_normalization_200[0][0]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_243[0][0]             \n",
      "                                                                 activation_245[0][0]             \n",
      "                                                                 activation_248[0][0]             \n",
      "                                                                 activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 25, 25, 64)   192         conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 25, 25, 64)   0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 25, 25, 96)   55296       activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 25, 25, 48)   144         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 25, 25, 96)   288         conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 25, 25, 48)   0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 25, 25, 96)   0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_20 (AveragePo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 25, 25, 64)   76800       activation_251[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 25, 25, 96)   82944       activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 25, 25, 64)   16384       average_pooling2d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 25, 25, 64)   192         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 25, 25, 64)   192         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 25, 25, 96)   288         conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 25, 25, 64)   192         conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 25, 25, 64)   0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 25, 25, 64)   0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 25, 25, 96)   0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 25, 25, 64)   0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_250[0][0]             \n",
      "                                                                 activation_252[0][0]             \n",
      "                                                                 activation_255[0][0]             \n",
      "                                                                 activation_256[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 25, 25, 64)   192         conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, 25, 25, 64)   0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 25, 25, 96)   55296       activation_260[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 25, 25, 48)   144         conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 25, 25, 96)   288         conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, 25, 25, 48)   0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, 25, 25, 96)   0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_21 (AveragePo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 25, 25, 64)   76800       activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 25, 25, 96)   82944       activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 25, 25, 64)   18432       average_pooling2d_21[0][0]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 25, 25, 64)   192         conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 25, 25, 64)   192         conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 25, 25, 96)   288         conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 25, 25, 64)   192         conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 25, 25, 64)   0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, 25, 25, 64)   0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, 25, 25, 96)   0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, 25, 25, 64)   0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_257[0][0]             \n",
      "                                                                 activation_259[0][0]             \n",
      "                                                                 activation_262[0][0]             \n",
      "                                                                 activation_263[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 25, 25, 64)   192         conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_265 (Activation)     (None, 25, 25, 64)   0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 25, 25, 96)   55296       activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 25, 25, 96)   288         conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_266 (Activation)     (None, 25, 25, 96)   0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 12, 12, 96)   82944       activation_266[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 12, 12, 384)  1152        conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 12, 12, 96)   288         conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, 12, 12, 384)  0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_267 (Activation)     (None, 12, 12, 96)   0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_264[0][0]             \n",
      "                                                                 activation_267[0][0]             \n",
      "                                                                 max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 12, 12, 128)  384         conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_272 (Activation)     (None, 12, 12, 128)  0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 12, 12, 128)  114688      activation_272[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 12, 12, 128)  384         conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_273 (Activation)     (None, 12, 12, 128)  0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 12, 12, 128)  114688      activation_273[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 12, 12, 128)  384         conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 12, 12, 128)  384         conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_269 (Activation)     (None, 12, 12, 128)  0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_274 (Activation)     (None, 12, 12, 128)  0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 12, 12, 128)  114688      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 12, 12, 128)  114688      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 12, 12, 128)  384         conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_226 (BatchN (None, 12, 12, 128)  384         conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_270 (Activation)     (None, 12, 12, 128)  0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, 12, 12, 128)  0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_22 (AveragePo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 12, 12, 192)  172032      activation_270[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 12, 12, 192)  172032      activation_275[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 12, 12, 192)  576         conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 12, 12, 192)  576         conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 12, 12, 192)  576         conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 12, 12, 192)  576         conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_268 (Activation)     (None, 12, 12, 192)  0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_271 (Activation)     (None, 12, 12, 192)  0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_276 (Activation)     (None, 12, 12, 192)  0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, 12, 12, 192)  0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_268[0][0]             \n",
      "                                                                 activation_271[0][0]             \n",
      "                                                                 activation_276[0][0]             \n",
      "                                                                 activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 12, 12, 160)  480         conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_282 (Activation)     (None, 12, 12, 160)  0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 12, 12, 160)  179200      activation_282[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 12, 12, 160)  480         conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_283 (Activation)     (None, 12, 12, 160)  0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 12, 12, 160)  179200      activation_283[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 12, 12, 160)  480         conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 12, 12, 160)  480         conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, 12, 12, 160)  0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_284 (Activation)     (None, 12, 12, 160)  0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 12, 12, 160)  179200      activation_279[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 12, 12, 160)  179200      activation_284[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 12, 12, 160)  480         conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 12, 12, 160)  480         conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, 12, 12, 160)  0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_285 (Activation)     (None, 12, 12, 160)  0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_23 (AveragePo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 12, 12, 192)  215040      activation_280[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 12, 12, 192)  215040      activation_285[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_23[0][0]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 12, 12, 192)  576         conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 12, 12, 192)  576         conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, 12, 12, 192)  576         conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 12, 12, 192)  576         conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, 12, 12, 192)  0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, 12, 12, 192)  0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_286 (Activation)     (None, 12, 12, 192)  0           batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_287 (Activation)     (None, 12, 12, 192)  0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_278[0][0]             \n",
      "                                                                 activation_281[0][0]             \n",
      "                                                                 activation_286[0][0]             \n",
      "                                                                 activation_287[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 12, 12, 160)  480         conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_292 (Activation)     (None, 12, 12, 160)  0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 12, 12, 160)  179200      activation_292[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 12, 12, 160)  480         conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_293 (Activation)     (None, 12, 12, 160)  0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 12, 12, 160)  179200      activation_293[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 12, 12, 160)  480         conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 12, 12, 160)  480         conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_289 (Activation)     (None, 12, 12, 160)  0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_294 (Activation)     (None, 12, 12, 160)  0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 12, 12, 160)  179200      activation_289[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 12, 12, 160)  179200      activation_294[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 12, 12, 160)  480         conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 12, 12, 160)  480         conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_290 (Activation)     (None, 12, 12, 160)  0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_295 (Activation)     (None, 12, 12, 160)  0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_24 (AveragePo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 12, 12, 192)  215040      activation_290[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 12, 12, 192)  215040      activation_295[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 12, 12, 192)  576         conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 12, 12, 192)  576         conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 12, 12, 192)  576         conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 12, 12, 192)  576         conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_288 (Activation)     (None, 12, 12, 192)  0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_291 (Activation)     (None, 12, 12, 192)  0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_296 (Activation)     (None, 12, 12, 192)  0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation_297 (Activation)     (None, 12, 12, 192)  0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_288[0][0]             \n",
      "                                                                 activation_291[0][0]             \n",
      "                                                                 activation_296[0][0]             \n",
      "                                                                 activation_297[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, 12, 12, 192)  576         conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_302 (Activation)     (None, 12, 12, 192)  0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 12, 12, 192)  258048      activation_302[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, 12, 12, 192)  576         conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_303 (Activation)     (None, 12, 12, 192)  0           batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 12, 12, 192)  258048      activation_303[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 12, 12, 192)  576         conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 12, 12, 192)  576         conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_299 (Activation)     (None, 12, 12, 192)  0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_304 (Activation)     (None, 12, 12, 192)  0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 12, 12, 192)  258048      activation_299[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 12, 12, 192)  258048      activation_304[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 12, 12, 192)  576         conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, 12, 12, 192)  576         conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_300 (Activation)     (None, 12, 12, 192)  0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_305 (Activation)     (None, 12, 12, 192)  0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_25 (AveragePo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 12, 12, 192)  258048      activation_300[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, 12, 12, 192)  258048      activation_305[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_258 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_25[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 12, 12, 192)  576         conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, 12, 12, 192)  576         conv2d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, 12, 12, 192)  576         conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_258 (BatchN (None, 12, 12, 192)  576         conv2d_258[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_298 (Activation)     (None, 12, 12, 192)  0           batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_301 (Activation)     (None, 12, 12, 192)  0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_306 (Activation)     (None, 12, 12, 192)  0           batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_307 (Activation)     (None, 12, 12, 192)  0           batch_normalization_258[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_298[0][0]             \n",
      "                                                                 activation_301[0][0]             \n",
      "                                                                 activation_306[0][0]             \n",
      "                                                                 activation_307[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_261 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_261 (BatchN (None, 12, 12, 192)  576         conv2d_261[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_310 (Activation)     (None, 12, 12, 192)  0           batch_normalization_261[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_262 (Conv2D)             (None, 12, 12, 192)  258048      activation_310[0][0]             \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_262 (BatchN (None, 12, 12, 192)  576         conv2d_262[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_311 (Activation)     (None, 12, 12, 192)  0           batch_normalization_262[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_259 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_263 (Conv2D)             (None, 12, 12, 192)  258048      activation_311[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_259 (BatchN (None, 12, 12, 192)  576         conv2d_259[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_263 (BatchN (None, 12, 12, 192)  576         conv2d_263[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_308 (Activation)     (None, 12, 12, 192)  0           batch_normalization_259[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_312 (Activation)     (None, 12, 12, 192)  0           batch_normalization_263[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_260 (Conv2D)             (None, 5, 5, 320)    552960      activation_308[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_264 (Conv2D)             (None, 5, 5, 192)    331776      activation_312[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_260 (BatchN (None, 5, 5, 320)    960         conv2d_260[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_264 (BatchN (None, 5, 5, 192)    576         conv2d_264[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_309 (Activation)     (None, 5, 5, 320)    0           batch_normalization_260[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_313 (Activation)     (None, 5, 5, 192)    0           batch_normalization_264[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_309[0][0]             \n",
      "                                                                 activation_313[0][0]             \n",
      "                                                                 max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_269 (Conv2D)             (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_269 (BatchN (None, 5, 5, 448)    1344        conv2d_269[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_318 (Activation)     (None, 5, 5, 448)    0           batch_normalization_269[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_266 (Conv2D)             (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_270 (Conv2D)             (None, 5, 5, 384)    1548288     activation_318[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_266 (BatchN (None, 5, 5, 384)    1152        conv2d_266[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_270 (BatchN (None, 5, 5, 384)    1152        conv2d_270[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_315 (Activation)     (None, 5, 5, 384)    0           batch_normalization_266[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_319 (Activation)     (None, 5, 5, 384)    0           batch_normalization_270[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_267 (Conv2D)             (None, 5, 5, 384)    442368      activation_315[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_268 (Conv2D)             (None, 5, 5, 384)    442368      activation_315[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_271 (Conv2D)             (None, 5, 5, 384)    442368      activation_319[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_272 (Conv2D)             (None, 5, 5, 384)    442368      activation_319[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_26 (AveragePo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_265 (Conv2D)             (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_267 (BatchN (None, 5, 5, 384)    1152        conv2d_267[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_268 (BatchN (None, 5, 5, 384)    1152        conv2d_268[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_271 (BatchN (None, 5, 5, 384)    1152        conv2d_271[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_272 (BatchN (None, 5, 5, 384)    1152        conv2d_272[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_273 (Conv2D)             (None, 5, 5, 192)    245760      average_pooling2d_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_265 (BatchN (None, 5, 5, 320)    960         conv2d_265[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_316 (Activation)     (None, 5, 5, 384)    0           batch_normalization_267[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_317 (Activation)     (None, 5, 5, 384)    0           batch_normalization_268[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_320 (Activation)     (None, 5, 5, 384)    0           batch_normalization_271[0][0]    \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation_321 (Activation)     (None, 5, 5, 384)    0           batch_normalization_272[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_273 (BatchN (None, 5, 5, 192)    576         conv2d_273[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_314 (Activation)     (None, 5, 5, 320)    0           batch_normalization_265[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_316[0][0]             \n",
      "                                                                 activation_317[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 5, 5, 768)    0           activation_320[0][0]             \n",
      "                                                                 activation_321[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_322 (Activation)     (None, 5, 5, 192)    0           batch_normalization_273[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_314[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_5[0][0]              \n",
      "                                                                 activation_322[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_278 (Conv2D)             (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_278 (BatchN (None, 5, 5, 448)    1344        conv2d_278[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_327 (Activation)     (None, 5, 5, 448)    0           batch_normalization_278[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_275 (Conv2D)             (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_279 (Conv2D)             (None, 5, 5, 384)    1548288     activation_327[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_275 (BatchN (None, 5, 5, 384)    1152        conv2d_275[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_279 (BatchN (None, 5, 5, 384)    1152        conv2d_279[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_324 (Activation)     (None, 5, 5, 384)    0           batch_normalization_275[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_328 (Activation)     (None, 5, 5, 384)    0           batch_normalization_279[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_276 (Conv2D)             (None, 5, 5, 384)    442368      activation_324[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_277 (Conv2D)             (None, 5, 5, 384)    442368      activation_324[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_280 (Conv2D)             (None, 5, 5, 384)    442368      activation_328[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_281 (Conv2D)             (None, 5, 5, 384)    442368      activation_328[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_27 (AveragePo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_274 (Conv2D)             (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_276 (BatchN (None, 5, 5, 384)    1152        conv2d_276[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_277 (BatchN (None, 5, 5, 384)    1152        conv2d_277[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_280 (BatchN (None, 5, 5, 384)    1152        conv2d_280[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_281 (BatchN (None, 5, 5, 384)    1152        conv2d_281[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_282 (Conv2D)             (None, 5, 5, 192)    393216      average_pooling2d_27[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_274 (BatchN (None, 5, 5, 320)    960         conv2d_274[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_325 (Activation)     (None, 5, 5, 384)    0           batch_normalization_276[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_326 (Activation)     (None, 5, 5, 384)    0           batch_normalization_277[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_329 (Activation)     (None, 5, 5, 384)    0           batch_normalization_280[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_330 (Activation)     (None, 5, 5, 384)    0           batch_normalization_281[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_282 (BatchN (None, 5, 5, 192)    576         conv2d_282[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_323 (Activation)     (None, 5, 5, 320)    0           batch_normalization_274[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_325[0][0]             \n",
      "                                                                 activation_326[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 5, 5, 768)    0           activation_329[0][0]             \n",
      "                                                                 activation_330[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_331 (Activation)     (None, 5, 5, 192)    0           batch_normalization_282[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_323[0][0]             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_6[0][0]              \n",
      "                                                                 activation_331[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished in 0.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6683417085427136, 0.6469354838709678)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "svm_bottleneck = SVC(\n",
    "    C=1.0,\n",
    "    gamma='auto',\n",
    "    probability=True,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    "    decision_function_shape='ovr'\n",
    ")\n",
    "'''\n",
    "svm_bottleneck = LinearSVC(penalty='l2', loss='squared_hinge', tol=0.0001, C=1.0, \n",
    "                           multi_class='ovr', verbose=0, max_iter=1000)\n",
    "\n",
    "\n",
    "t0 = time.time()\n",
    "#svm_bottleneck.fit(train_x_lda, train_y) # 86 89\n",
    "svm_bottleneck.fit(train_x_pca, train_y) # 95 94\n",
    "#svm_bottleneck.fit(train_x, train_y) # 94 94\n",
    "print('finished in %.1fs' % (time.time() - t0))\n",
    "\n",
    "#val_x_lda = lda.transform(val_x)\n",
    "#svm_preds = svm_bottleneck.predict(val_x_lda)\n",
    "val_x_pca = pca.transform(val_x)\n",
    "svm_preds = svm_bottleneck.predict(val_x_pca)\n",
    "#svm_preds = svm_bottleneck.predict(val_x)\n",
    "\n",
    "accuracy_score(val_y, svm_preds), f1_score(val_y, svm_preds, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished in 39.92s\n"
     ]
    }
   ],
   "source": [
    "# fit on train data\n",
    "t0 = time.time()\n",
    "svm_bottleneck.fit(train_x, train_y)\n",
    "print('finished in %.2fs' % (time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished in 4.69s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "preds = svm_bottleneck.predict(val_x)\n",
    "print('finished in %.2fs' % (time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished in 4.41s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "preds_prob = svm_bottleneck.predict_proba(val_x)\n",
    "print('finished in %.2fs' % (time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.62043778e-05, 9.99983796e-01])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_prob[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished in 4.57s\n",
      "finished in 0.00s\n",
      "finished in 0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6030150753768844, 0.5432199203881803)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test on validation data\n",
    "t0 = time.time()\n",
    "preds = svm_bottleneck.predict(val_x)\n",
    "print('finished in %.2fs' % (time.time() - t0))\n",
    "\n",
    "t0 = time.time()\n",
    "acc = accuracy_score(val_y, preds)\n",
    "print('finished in %.2fs' % (time.time() - t0))\n",
    "\n",
    "t0 = time.time()\n",
    "f1 = f1_score(val_y, preds, average='macro')\n",
    "print('finished in %.2fs' % (time.time() - t0))\n",
    "\n",
    "acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving a backup of the previously trained svm just in case\n",
    "svm_bottleneck_bottleneck = svm_bottleneck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished in 40.8s\n",
      "0.5577889447236181 0.5568825910931174\n",
      "0.4824120603015075 0.32542372881355935\n",
      "0.6030150753768844 0.5432199203881803\n"
     ]
    }
   ],
   "source": [
    "val_x_lda = lda.transform(X_validation)\n",
    "\n",
    "\n",
    "svms = [SVC(C=1.0, gamma='auto', probability=True, tol=0.001, \n",
    "            verbose=False, decision_function_shape='ovr') for _ in range(3)]\n",
    "\n",
    "t0 = time.time()\n",
    "svms[0].fit(train_x_lda, train_y) # \n",
    "svms[1].fit(train_x_pca, train_y) # \n",
    "svms[2].fit(train_x, train_y)     # \n",
    "print('finished in %.1fs' % (time.time() - t0))\n",
    "\n",
    "test_x_lda = lda.transform(X_test)\n",
    "test_x_pca = pca.transform(X_test)\n",
    "\n",
    "lda_preds  = svms[0].predict(val_x_lda)\n",
    "pca_preds  = svms[1].predict(val_x_pca)\n",
    "nodr_preds = svms[2].predict(val_x)\n",
    "\n",
    "print(accuracy_score(val_y, lda_preds), f1_score(val_y, lda_preds, average='macro'))\n",
    "print(accuracy_score(val_y, pca_preds), f1_score(val_y, pca_preds, average='macro'))\n",
    "print(accuracy_score(val_y, nodr_preds), f1_score(val_y, nodr_preds, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBF SVC variance estimated s^2 = (0.003)^2\n",
    "\n",
    "def inverse_variance_weighting(predictions, variances):\n",
    "    if len(predictions) != len(variances):\n",
    "        print('Precictions-variances mismatch.')\n",
    "        sys.exit(0)\n",
    "    \n",
    "    aa = np.sum(np.divide(predictions, variances))\n",
    "    bb = 1 / np.sum(variances)\n",
    "    \n",
    "    return aa / bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[<keras.engine.sequential.Sequential object at 0x00000171DD2AEA20>, SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)],\n",
       "         flatten_transform=None, n_jobs=None, voting='hard', weights=None)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf = VotingClassifier([model, svm_bottleneck])  # (inception model (first top model))\n",
    "voting_clf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # open sved history\n",
    "# with open('inception_v3_spoton.historydf.pickle', 'rb') as f:\n",
    "#     historydf = pickle.load(f)\n",
    "\n",
    "# historydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc = historydf['categorical_accuracy']\n",
    "# val_acc = historydf['val_categorical_accuracy']\n",
    "# loss = historydf['loss']\n",
    "# val_loss = historydf['val_loss']\n",
    "\n",
    "# epochs = range(len(acc))\n",
    " \n",
    "# plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "# plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "# plt.title('Training and validation accuracy')\n",
    "# plt.legend()\n",
    "# plt.savefig('img/inception_acc.png')\n",
    "\n",
    "# plt.figure()\n",
    " \n",
    "# plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "# plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "# plt.title('Training and validation loss')\n",
    "# plt.legend()\n",
    "# plt.savefig('img/inception_loss.png')\n",
    " \n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
